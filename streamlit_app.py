import os
import streamlit as st
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° ì„¤ì •
load_dotenv()
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

# ëª¨ë“ˆ import (êµ¬ì¡° ê¸°ë°˜)
from core.rag_engine import init_rag, ask_rag_question, ask_gpt_fallback
from meditation.loader import show_meditation_menu
from meditation.reader import read_meditation_text
from audio.tts import TTSClient
from audio.transcriber import transcribe_audio
from realtime_audio import AudioFrameRecorder
from streamlit_webrtc import webrtc_streamer, WebRtcMode

# TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
tts = TTSClient()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì‚¬í‹° ì±—ë´‡", layout="centered")
st.title("ğŸ§˜ ì‚¬í‹° ë§ˆìŒì±™ê¹€ ì±—ë´‡")
st.markdown("ì‚¬í‹°ëŠ” ë‹¹ì‹ ì˜ ë‚´ë©´ì„ ìœ„í•œ ì¡°ìš©í•œ ì¹œêµ¬ì…ë‹ˆë‹¤.")

# ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ë©”ë‰´ ì„ íƒ
mode = st.radio("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:", ["í…ìŠ¤íŠ¸ ì±„íŒ…", "ìŒì„± ì±„íŒ…", "ëª…ìƒë¬¸"])

def handle_text_chat():
    st.subheader("ğŸ’¬ ì‚¬í‹°ì™€ ì±„íŒ…í•˜ì„¸ìš”")
    user_input = st.chat_input("ì‚¬í‹°ì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”")

    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})

        with st.chat_message("assistant"):
            with st.spinner("ì‚¬í‹°ê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
                rag_chain = init_rag("Mindfulness RAG")
                answer = ask_gpt_fallback(st.session_state.messages)
                if not answer or "ëª¨ë¥´ê² " in answer:
                    st.info("ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ ë” ë‚˜ì€ ë‹µë³€ì„ ì°¾ìŠµë‹ˆë‹¤.")
                    answer = ask_rag_question(rag_chain, user_input)

                st.markdown(answer)
                tts.speak(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})

def handle_voice_chat():
    st.subheader("ğŸ¤ ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³  ì‚¬í‹°ì˜ ìŒì„±ì„ ë“¤ì–´ë³´ì„¸ìš”")

    input_mode = st.radio("ì…ë ¥ ë°©ì‹ ì„ íƒ", ["íŒŒì¼ ì—…ë¡œë“œ", "ì‹¤ì‹œê°„ ë§ˆì´í¬"])

    if input_mode == "íŒŒì¼ ì—…ë¡œë“œ":
        uploaded_file = st.file_uploader("WAV ë˜ëŠ” MP3 íŒŒì¼ ì—…ë¡œë“œ", type=["wav", "mp3"])
        if uploaded_file:
            with open("temp_audio.wav", "wb") as f:
                f.write(uploaded_file.read())
            try:
                user_input = transcribe_audio("temp_audio.wav")
                st.success(f"ğŸ—£ï¸ ì¸ì‹ëœ ì§ˆë¬¸: {user_input}")
                st.session_state.messages.append({"role": "user", "content": user_input})

                with st.chat_message("assistant"):
                    with st.spinner("ì‚¬í‹°ê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤..."):
                        rag_chain = init_rag("Mindfulness RAG")
                        answer = ask_gpt_fallback(st.session_state.messages)
                        if not answer or "ëª¨ë¥´ê² " in answer:
                            st.info("ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ ë” ë‚˜ì€ ë‹µë³€ì„ ì°¾ìŠµë‹ˆë‹¤.")
                            answer = ask_rag_question(rag_chain, user_input)

                        st.markdown(answer)
                        tts.speak(answer)
                        st.session_state.messages.append({"role": "assistant", "content": answer})
            except Exception as e:
                st.error(f"ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    elif input_mode == "ì‹¤ì‹œê°„ ë§ˆì´í¬":
        st.info("ë§ˆì´í¬ì— ëŒ€ê³  ë§ì”€í•´ì£¼ì„¸ìš”. ì¤‘ì§€ í›„ ë¶„ì„ë©ë‹ˆë‹¤.")
        recorder = AudioFrameRecorder()
        webrtc_ctx = webrtc_streamer(
            key="speech",
            mode=WebRtcMode.SENDONLY,
            audio_receiver_size=1024,
            audio_frame_callback=recorder,
        )

        if st.button("â¹ï¸ ë…¹ìŒ ì¤‘ì§€ ë° ì²˜ë¦¬"):
            filepath = recorder.save_wav()
            if filepath:
                st.audio(filepath, format="audio/wav")
                try:
                    user_input = transcribe_audio(filepath)
                    st.success(f"ğŸ—£ï¸ ì¸ì‹ëœ ì§ˆë¬¸: {user_input}")
                    st.session_state.messages.append({"role": "user", "content": user_input})

                    with st.chat_message("assistant"):
                        with st.spinner("ì‚¬í‹°ê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤..."):
                            rag_chain = init_rag("Mindfulness RAG")
                            answer = ask_gpt_fallback(st.session_state.messages)
                            if not answer or "ëª¨ë¥´ê² " in answer:
                                st.info("ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ ë” ë‚˜ì€ ë‹µë³€ì„ ì°¾ìŠµë‹ˆë‹¤.")
                                answer = ask_rag_question(rag_chain, user_input)

                            st.markdown(answer)
                            tts.speak(answer)
                            st.session_state.messages.append({"role": "assistant", "content": answer})
                except Exception as e:
                    st.error(f"âŒ Whisper ì˜¤ë¥˜: {e}")

def handle_meditation():
    st.subheader("ğŸ§˜ ëª…ìƒë¬¸ ë³´ê¸° ë° ë“£ê¸°")
    try:
        filepath = show_meditation_menu("mindfulness meditation")
        if filepath:
            content = read_meditation_text(filepath)
            st.text_area("ëª…ìƒë¬¸ ë‚´ìš©", content, height=300)
            tts.speak(content, is_meditation=True)
    except Exception as e:
        st.error(f"ëª…ìƒë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ë©”ì¸ ì‹¤í–‰ ë¶„ê¸°
if mode == "í…ìŠ¤íŠ¸ ì±„íŒ…":
    handle_text_chat()
elif mode == "ìŒì„± ì±„íŒ…":
    handle_voice_chat()
elif mode == "ëª…ìƒë¬¸":
    handle_meditation()
